{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wheeze_dataframe = pd.read_csv(\"./Wheeze.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.903289</td>\n",
       "      <td>-1.369677</td>\n",
       "      <td>1.221657</td>\n",
       "      <td>-0.251466</td>\n",
       "      <td>0.475389</td>\n",
       "      <td>-0.536943</td>\n",
       "      <td>0.495690</td>\n",
       "      <td>0.422024</td>\n",
       "      <td>-0.146817</td>\n",
       "      <td>0.407348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.026604</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.738906</td>\n",
       "      <td>-1.599669</td>\n",
       "      <td>0.743576</td>\n",
       "      <td>-0.187029</td>\n",
       "      <td>0.723137</td>\n",
       "      <td>-0.572496</td>\n",
       "      <td>0.807697</td>\n",
       "      <td>0.391983</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.434328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024419</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>0.020583</td>\n",
       "      <td>0.021060</td>\n",
       "      <td>0.022686</td>\n",
       "      <td>0.021391</td>\n",
       "      <td>0.020606</td>\n",
       "      <td>0.019174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415531</td>\n",
       "      <td>-1.786016</td>\n",
       "      <td>1.248152</td>\n",
       "      <td>-0.300725</td>\n",
       "      <td>0.533205</td>\n",
       "      <td>-0.510882</td>\n",
       "      <td>0.643205</td>\n",
       "      <td>0.188655</td>\n",
       "      <td>-0.151871</td>\n",
       "      <td>0.712749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>0.022452</td>\n",
       "      <td>0.021682</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.022538</td>\n",
       "      <td>-1.806340</td>\n",
       "      <td>1.558155</td>\n",
       "      <td>-0.192655</td>\n",
       "      <td>0.383104</td>\n",
       "      <td>-0.392252</td>\n",
       "      <td>0.631755</td>\n",
       "      <td>0.160329</td>\n",
       "      <td>-0.165993</td>\n",
       "      <td>0.659677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023901</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.022787</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>0.020583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697508</td>\n",
       "      <td>-0.913479</td>\n",
       "      <td>1.209479</td>\n",
       "      <td>-0.257466</td>\n",
       "      <td>0.458489</td>\n",
       "      <td>-0.592923</td>\n",
       "      <td>0.530187</td>\n",
       "      <td>0.178539</td>\n",
       "      <td>-0.021558</td>\n",
       "      <td>0.428705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023267</td>\n",
       "      <td>0.024999</td>\n",
       "      <td>0.023306</td>\n",
       "      <td>0.025425</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.023378</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.184472</td>\n",
       "      <td>1.911060</td>\n",
       "      <td>0.191612</td>\n",
       "      <td>0.476283</td>\n",
       "      <td>0.333363</td>\n",
       "      <td>0.853831</td>\n",
       "      <td>1.126811</td>\n",
       "      <td>1.124128</td>\n",
       "      <td>0.644864</td>\n",
       "      <td>0.373621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026604</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.021362</td>\n",
       "      <td>0.022181</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.922573</td>\n",
       "      <td>2.107249</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.326879</td>\n",
       "      <td>0.337991</td>\n",
       "      <td>0.828022</td>\n",
       "      <td>1.104772</td>\n",
       "      <td>1.028151</td>\n",
       "      <td>0.628726</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024442</td>\n",
       "      <td>0.021651</td>\n",
       "      <td>0.023939</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>0.021612</td>\n",
       "      <td>0.022796</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.020818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.108947</td>\n",
       "      <td>1.480177</td>\n",
       "      <td>0.233653</td>\n",
       "      <td>0.085076</td>\n",
       "      <td>0.152412</td>\n",
       "      <td>0.600708</td>\n",
       "      <td>0.989603</td>\n",
       "      <td>1.203239</td>\n",
       "      <td>0.661336</td>\n",
       "      <td>0.380111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.020755</td>\n",
       "      <td>0.022038</td>\n",
       "      <td>0.021585</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.020749</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.768019</td>\n",
       "      <td>1.238749</td>\n",
       "      <td>0.044463</td>\n",
       "      <td>0.065454</td>\n",
       "      <td>0.062633</td>\n",
       "      <td>0.358854</td>\n",
       "      <td>1.146558</td>\n",
       "      <td>1.192159</td>\n",
       "      <td>0.706433</td>\n",
       "      <td>0.340689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023508</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.019567</td>\n",
       "      <td>0.019857</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>0.021214</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.290695</td>\n",
       "      <td>1.178580</td>\n",
       "      <td>0.255461</td>\n",
       "      <td>0.290857</td>\n",
       "      <td>0.193202</td>\n",
       "      <td>0.370412</td>\n",
       "      <td>0.863560</td>\n",
       "      <td>1.005467</td>\n",
       "      <td>0.565294</td>\n",
       "      <td>0.400942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.026269</td>\n",
       "      <td>0.027077</td>\n",
       "      <td>0.024283</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>0.023001</td>\n",
       "      <td>0.026636</td>\n",
       "      <td>0.023119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.975342</td>\n",
       "      <td>1.829245</td>\n",
       "      <td>0.295055</td>\n",
       "      <td>0.330513</td>\n",
       "      <td>0.204254</td>\n",
       "      <td>0.587736</td>\n",
       "      <td>0.912214</td>\n",
       "      <td>1.111716</td>\n",
       "      <td>0.749598</td>\n",
       "      <td>0.430307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023505</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.023151</td>\n",
       "      <td>0.021699</td>\n",
       "      <td>0.021996</td>\n",
       "      <td>0.020756</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.905472</td>\n",
       "      <td>1.938907</td>\n",
       "      <td>0.153869</td>\n",
       "      <td>0.273839</td>\n",
       "      <td>0.152569</td>\n",
       "      <td>0.632577</td>\n",
       "      <td>0.873225</td>\n",
       "      <td>1.023067</td>\n",
       "      <td>0.726859</td>\n",
       "      <td>0.431365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025373</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.020025</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>0.021140</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.019654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.167131</td>\n",
       "      <td>1.779429</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>0.317908</td>\n",
       "      <td>0.210902</td>\n",
       "      <td>0.631897</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.905640</td>\n",
       "      <td>0.689377</td>\n",
       "      <td>0.526180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>0.020249</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>0.019327</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>0.018822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.792200</td>\n",
       "      <td>1.964792</td>\n",
       "      <td>0.290195</td>\n",
       "      <td>0.374964</td>\n",
       "      <td>0.250967</td>\n",
       "      <td>0.747159</td>\n",
       "      <td>0.847106</td>\n",
       "      <td>0.993875</td>\n",
       "      <td>0.727049</td>\n",
       "      <td>0.485355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.019568</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.124892</td>\n",
       "      <td>1.838047</td>\n",
       "      <td>0.302104</td>\n",
       "      <td>0.390627</td>\n",
       "      <td>0.197476</td>\n",
       "      <td>0.742028</td>\n",
       "      <td>0.995597</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>0.755314</td>\n",
       "      <td>0.485899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>0.021551</td>\n",
       "      <td>0.021732</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.903289 -1.369677  1.221657 -0.251466  0.475389 -0.536943  0.495690   \n",
       "1   1.738906 -1.599669  0.743576 -0.187029  0.723137 -0.572496  0.807697   \n",
       "2  -0.415531 -1.786016  1.248152 -0.300725  0.533205 -0.510882  0.643205   \n",
       "3  -0.022538 -1.806340  1.558155 -0.192655  0.383104 -0.392252  0.631755   \n",
       "4   0.697508 -0.913479  1.209479 -0.257466  0.458489 -0.592923  0.530187   \n",
       "5   4.184472  1.911060  0.191612  0.476283  0.333363  0.853831  1.126811   \n",
       "6   3.922573  2.107249  0.101726  0.326879  0.337991  0.828022  1.104772   \n",
       "7   4.108947  1.480177  0.233653  0.085076  0.152412  0.600708  0.989603   \n",
       "8   3.768019  1.238749  0.044463  0.065454  0.062633  0.358854  1.146558   \n",
       "9   3.290695  1.178580  0.255461  0.290857  0.193202  0.370412  0.863560   \n",
       "10  2.975342  1.829245  0.295055  0.330513  0.204254  0.587736  0.912214   \n",
       "11  2.905472  1.938907  0.153869  0.273839  0.152569  0.632577  0.873225   \n",
       "12  3.167131  1.779429  0.017437  0.317908  0.210902  0.631897  0.778185   \n",
       "13  2.792200  1.964792  0.290195  0.374964  0.250967  0.747159  0.847106   \n",
       "14  3.124892  1.838047  0.302104  0.390627  0.197476  0.742028  0.995597   \n",
       "\n",
       "           7         8         9  ...       208       209       210       211  \\\n",
       "0   0.422024 -0.146817  0.407348  ...  0.025327  0.026604  0.024097  0.022313   \n",
       "1   0.391983  0.020661  0.434328  ...  0.024419  0.023467  0.020583  0.021060   \n",
       "2   0.188655 -0.151871  0.712749  ...  0.024223  0.027386  0.025254  0.022452   \n",
       "3   0.160329 -0.165993  0.659677  ...  0.023901  0.022149  0.023217  0.024684   \n",
       "4   0.178539 -0.021558  0.428705  ...  0.023267  0.024999  0.023306  0.025425   \n",
       "5   1.124128  0.644864  0.373621  ...  0.026604  0.023800  0.024348  0.020301   \n",
       "6   1.028151  0.628726  0.375484  ...  0.024442  0.021651  0.023939  0.020085   \n",
       "7   1.203239  0.661336  0.380111  ...  0.025555  0.020755  0.022038  0.021585   \n",
       "8   1.192159  0.706433  0.340689  ...  0.023508  0.022894  0.019567  0.019857   \n",
       "9   1.005467  0.565294  0.400942  ...  0.029853  0.026269  0.027077  0.024283   \n",
       "10  1.111716  0.749598  0.430307  ...  0.023505  0.022053  0.023151  0.021699   \n",
       "11  1.023067  0.726859  0.431365  ...  0.025373  0.022688  0.020025  0.021135   \n",
       "12  0.905640  0.689377  0.526180  ...  0.025044  0.022165  0.021263  0.020249   \n",
       "13  0.993875  0.727049  0.485355  ...  0.033175  0.023423  0.024382  0.019568   \n",
       "14  1.097825  0.755314  0.485899  ...  0.023964  0.024339  0.021551  0.021732   \n",
       "\n",
       "         212       213       214       215  216  \\\n",
       "0   0.024161  0.023309  0.021515  0.020085  1.0   \n",
       "1   0.022686  0.021391  0.020606  0.019174  1.0   \n",
       "2   0.021682  0.020022  0.020008  0.021050  1.0   \n",
       "3   0.021610  0.022787  0.022379  0.020583  1.0   \n",
       "4   0.019984  0.022800  0.023378  0.017733  1.0   \n",
       "5   0.021362  0.022181  0.021636  0.020556  0.0   \n",
       "6   0.021612  0.022796  0.020327  0.020818  0.0   \n",
       "7   0.020250  0.020749  0.021525  0.020780  0.0   \n",
       "8   0.020446  0.021214  0.019215  0.020215  0.0   \n",
       "9   0.022689  0.023001  0.026636  0.023119  0.0   \n",
       "10  0.021996  0.020756  0.020982  0.019564  0.0   \n",
       "11  0.021140  0.019253  0.017751  0.019654  0.0   \n",
       "12  0.020026  0.019327  0.019180  0.018822  0.0   \n",
       "13  0.018248  0.022286  0.019935  0.020762  0.0   \n",
       "14  0.018842  0.023229  0.019117  0.020380  0.0   \n",
       "\n",
       "                                                  217  \n",
       "0   2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...  \n",
       "1   2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...  \n",
       "2   2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...  \n",
       "3   2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...  \n",
       "4   2018_08_21_12_40_EllammaK_P_Asthma_F_before_48...  \n",
       "5   2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "6   2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "7   2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "8   2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "9   2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "10  2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "11  2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "12  2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "13  2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "14  2017_01_12_10_45_Priyanka_C_Na_F_Na_28_160_59_...  \n",
       "\n",
       "[15 rows x 218 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wheeze_dataframe.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657, 218)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wheeze_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    332\n",
       "0.0    325\n",
       "Name: 216, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wheeze_dataframe['216'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>...</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "      <td>657.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.96</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.61</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.06</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-2.01</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.26</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.18</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.33</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6       7       8  \\\n",
       "count  657.00  657.00  657.00  657.00  657.00  657.00  657.00  657.00  657.00   \n",
       "mean     2.96   -0.11    0.94   -0.04    0.70    0.12    0.41    0.25    0.17   \n",
       "std      1.61    0.90    0.68    0.59    0.48    0.40    0.41    0.36    0.30   \n",
       "min     -2.06   -3.40   -0.86   -2.01   -0.84   -0.94   -0.88   -0.62   -0.89   \n",
       "25%      1.89   -0.70    0.44   -0.38    0.38   -0.13    0.15    0.01   -0.01   \n",
       "50%      3.26   -0.12    1.01    0.01    0.75    0.10    0.35    0.25    0.16   \n",
       "75%      4.18    0.53    1.43    0.37    1.05    0.36    0.61    0.47    0.31   \n",
       "max      6.33    2.38    2.93    1.50    2.04    1.24    1.95    1.61    1.24   \n",
       "\n",
       "            9  ...     207     208     209     210     211     212     213  \\\n",
       "count  657.00  ...  657.00  657.00  657.00  657.00  657.00  657.00  657.00   \n",
       "mean    -0.02  ...    0.03    0.03    0.03    0.02    0.02    0.02    0.02   \n",
       "std      0.30  ...    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "min     -1.27  ...    0.02    0.02    0.02    0.02    0.02    0.02    0.02   \n",
       "25%     -0.19  ...    0.03    0.02    0.02    0.02    0.02    0.02    0.02   \n",
       "50%      0.00  ...    0.03    0.03    0.03    0.02    0.02    0.02    0.02   \n",
       "75%      0.19  ...    0.03    0.03    0.03    0.03    0.03    0.02    0.02   \n",
       "max      0.71  ...    0.04    0.04    0.04    0.04    0.03    0.03    0.03   \n",
       "\n",
       "          214     215     216  \n",
       "count  657.00  657.00  657.00  \n",
       "mean     0.02    0.02    0.51  \n",
       "std      0.00    0.00    0.50  \n",
       "min      0.02    0.02    0.00  \n",
       "25%      0.02    0.02    0.00  \n",
       "50%      0.02    0.02    1.00  \n",
       "75%      0.02    0.02    1.00  \n",
       "max      0.03    0.03    1.00  \n",
       "\n",
       "[8 rows x 217 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(Wheeze_dataframe.describe(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Wheeze_dataframe.iloc[:,:216]\n",
    "y = Wheeze_dataframe.iloc[:,216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 216)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 216)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525,), (132,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIthout Scaling + Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.7955\n",
      "Training-set accuracy score: 0.7886\n"
     ]
    }
   ],
   "source": [
    "svc_default = SVC()\n",
    "svc_default.fit(X_train,y_train)\n",
    "y_pred_default = svc_default.predict(X_test)\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred_default)))\n",
    "y_pred_train = svc_default.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Scaling + Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.8939\n",
      "Training-set accuracy score: 0.9790\n"
     ]
    }
   ],
   "source": [
    "svc_default_scaled = SVC()\n",
    "svc_default_scaled.fit(X_train,y_train)\n",
    "y_pred_default = svc_default_scaled.predict(X_test)\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred_default)))\n",
    "y_pred_train = svc_default_scaled.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=1000.0 : 0.8864\n",
      "Training-set accuracy score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(C=1000.0) \n",
    "\n",
    "\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "\n",
    "print('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "y_pred_train = svc.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.7879\n",
      "Training-set accuracy score: 0.9733\n"
     ]
    }
   ],
   "source": [
    "linear_svc=SVC(kernel='linear', C=1.0) \n",
    "linear_svc.fit(X_train,y_train)\n",
    "y_pred_linear = linear_svc.predict(X_test)\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_linear)))\n",
    "y_pred_train = linear_svc.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.7652\n",
      "Training-set accuracy score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "linear_svc100 =SVC(kernel='linear', C=100.0) \n",
    "linear_svc100.fit(X_train,y_train)\n",
    "y_pred_linear = linear_svc100.predict(X_test)\n",
    "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_linear)))\n",
    "y_pred_train = linear_svc100.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with polynomial kernel and C=1.0 : 0.7955\n",
      "Training-set accuracy score: 0.9448\n"
     ]
    }
   ],
   "source": [
    "poly_svc = SVC(kernel = 'poly')\n",
    "poly_svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_poly = poly_svc.predict(X_test)\n",
    "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_poly)))\n",
    "\n",
    "y_pred_train = poly_svc.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with polynomial kernel and C=100.0 : 0.9015\n",
      "Training-set accuracy score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "poly_svc = SVC(kernel = 'poly', C = 100)\n",
    "poly_svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_poly = poly_svc.predict(X_test)\n",
    "print('Model accuracy score with polynomial kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_poly)))\n",
    "\n",
    "y_pred_train = poly_svc.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with sigmoid kernel and C=1.0 : 0.7652\n",
      "Training-set accuracy score: 0.7676\n"
     ]
    }
   ],
   "source": [
    "sigmoid_svc = SVC(kernel = 'sigmoid')\n",
    "sigmoid_svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_poly = sigmoid_svc.predict(X_test)\n",
    "print('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_poly)))\n",
    "\n",
    "y_pred_train = sigmoid_svc.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with sigmoid kernel and C=100.0 : 0.6742\n",
      "Training-set accuracy score: 0.7219\n"
     ]
    }
   ],
   "source": [
    "sigmoid_svc = SVC(kernel = 'sigmoid', C = 100)\n",
    "sigmoid_svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_poly = sigmoid_svc.predict(X_test)\n",
    "print('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_poly)))\n",
    "\n",
    "y_pred_train = sigmoid_svc.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling improves the accuracy, need to find out whether the same is for K fold, RBF, values of Gamma and C yet to decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.8939\n",
      "Training-set accuracy score: 0.9790\n"
     ]
    }
   ],
   "source": [
    "svc_scaled = SVC()\n",
    "svc_scaled.fit(X_train,y_train)\n",
    "y_pred = svc_scaled.predict(X_test)\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "y_pred_train = svc_scaled.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[58  9]\n",
      " [ 5 60]]\n",
      "\n",
      "True Positives(TP) =  58\n",
      "\n",
      "True Negatives(TN) =  60\n",
      "\n",
      "False Positives(FP) =  9\n",
      "\n",
      "False Negatives(FN) =  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.87      0.89        67\n",
      "         1.0       0.87      0.92      0.90        65\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       132\n",
      "   macro avg       0.90      0.89      0.89       132\n",
      "weighted avg       0.90      0.89      0.89       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred_default)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "kfold_svc = SVC()\n",
    "default_kfold_scores = cross_val_score(kfold_svc,X,y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77272727, 0.71969697, 0.80916031, 0.80152672, 0.77099237])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_kfold_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7701943095072866"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_kfold_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "# X_test = pd.DataFrame(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "kfold_svc_scaled = SVC()\n",
    "Scaled_kfold_scores = cross_val_score(kfold_svc_scaled,X_scaled,y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85606061, 0.83333333, 0.83206107, 0.8778626 , 0.83206107])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaled_kfold_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8462757344436735"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaled_kfold_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "              'kernel': ['rbf']}  \n",
    "\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, scoring='accuracy', cv = kfold, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansh/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9193302891933028"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
